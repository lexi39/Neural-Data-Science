{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "082087159a10145c95fbbd988b11fff2",
     "grade": false,
     "grade_id": "cell-cbcf6d0722b4332d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3: Neuroscience Literature Mining\n",
    "\n",
    "This assignment will demonstrate how to pull data from an API, how to work with the LISC package, and test your knowledge of working with classes and numpy.\n",
    "\n",
    "This assignment is worth 5 points (5% of your grade). \n",
    "\n",
    "**PLEASE DO NOT CHANGE THE NAME OF THIS FILE.**\n",
    "\n",
    "**PLEASE DO NOT COPY & PASTE OR DELETE CELLS INCLUDED IN THE ASSIGNMENT.**\n",
    "\n",
    "\n",
    "## How to complete assignments\n",
    "\n",
    "Whenever you see:\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "You need to **replace (meaning, delete) these lines of code with code that answers the questions** and meets the specified criteria. Make sure you remove the 'raise' line when you do this (or your notebook will raise an error, regardless of any other code, and thus fail the grading tests).\n",
    "\n",
    "You should write the answer to the questions in those cells (the ones with `# YOUR CODE HERE`), but you can also add extra cells to explore / investigate things if you need / want to. \n",
    "\n",
    "Any cell with `assert` statements in it is a test cell. You should not try to change or delete these cells. Note that there might be more than one assert that tests a particular question. \n",
    "\n",
    "If a test does fail, reading the error that is printed out should let you know which test failed, which may be useful for fixing it.\n",
    "\n",
    "Note that some cells, including the test cells, may be read only, which means they won't let you edit them. If you cannot edit a cell - that is normal, and you shouldn't need to edit that cell.\n",
    "\n",
    "\n",
    "## Tips & Tricks\n",
    "\n",
    "The following are a couple tips & tricks that may help you if you get stuck on anything.\n",
    "\n",
    "#### Printing Variables\n",
    "You can (and should) print and check variables as you go. This allows you to check what values they hold, and fix things if anything unexpected happens.\n",
    "\n",
    "#### Restarting the Kernel\n",
    "- If you run cells out of order, you can end up overwriting things in your namespace. \n",
    "- If things seem to go weird, a good first step is to restart the kernel, which you can do from the kernel menu above.\n",
    "- Even if everything seems to be working, it's a nice check to 'Restart & Run All', to make sure everything runs properly in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee2162911e44d29b86547006186e2452",
     "grade": false,
     "grade_id": "cell-9a80f9f3295cb2ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1: Fetching data from URLs\n",
    "\n",
    "In this section we'll show you the very basics of how to look up how many articles are indexed in Pubmed that have specific words or phrases (n-grams) in their titles and/or abstracts.\n",
    "\n",
    "For this example, we begin by counting how many articles have been published whose titles or abstracts contain the phrases \"working memory\" or \"short term memory\". Look through the cell below to get a sense of what it is doing, and then run the cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\\n<eSearchResult>\\n\\t<Count>38800</Count>\\n</eSearchResult>\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request # default library for requesting data from URLs\n",
    "\n",
    "# this is the base URL for making use of the NIH NLM database search API\n",
    "u_eutils = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "\n",
    "##### all of the code that follows is to construct the full search URL #####\n",
    "\n",
    "# what database to search; here, pubmed\n",
    "u_db = 'db=pubmed'\n",
    "\n",
    "# what information to return; here, count of the number of articles\n",
    "u_rettype = 'rettype=count'\n",
    "\n",
    "# what field to search; here, tiab (pubmed's code for TItle and ABstract)\n",
    "u_field = 'field=tiab'\n",
    "\n",
    "# what term(s) to search for; here \"working memory\" OR \"short term memory\"\n",
    "# note that the double quotes around the phrases indicate we only want to return\n",
    "    # searches that contain that exact phrase\n",
    "u_term = 'term='\n",
    "url_searchterms = '\"working memory\" OR \"short term memory\"'\n",
    "url_searchterms = url_searchterms.replace(' ', '+') # URLs don't do spaces; replace with +\n",
    "u_term = u_term + url_searchterms\n",
    "\n",
    "# stitch the URL together from the parts we gave it\n",
    "url = u_eutils + '?' + u_db + '&' + u_rettype + '&' + u_field + '&' + u_term\n",
    "\n",
    "##### end URL construction block #####\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    xml = response.read()\n",
    "xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "463d3cd60513c061743b1b74c8d13e65",
     "grade": false,
     "grade_id": "cell-9f9158654e4502e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1: Making your own search\n",
    "\n",
    "You can see, between the `<Count>` tags in the long response above, that this returns (on January 30th, 2020) 38763 articles in Pubmed with the phrases \"working memory\" or \"short term memory\" in their titles and/or abstracts. This number, of course, will keep increasing over time (and might have increased since we released the assignment!).\n",
    "\n",
    "1. Use the eutils documentation, specifically the esearch tools [here](https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch) and [here](https://www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.Title_TI), to modify the above code to find the count of how many articles have been published with the following three terms <font color='red'>**in their titles only**</font>:\n",
    "\n",
    "    * dentate gyrus\n",
    "    * entorhinal cortex\n",
    "    * subiculum\n",
    "\n",
    "\n",
    "2. In the cell below the url creation cell (after you've retrieved the xml) create a new variable, `number_of_articles`, that lists that count (as an integer). Remember the double quotes around the phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a78d9ceef7fc6cbf50049f6afc84a1f7",
     "grade": false,
     "grade_id": "cell-de51725c9709625a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<!DOCTYPE eSearchResult PUBLIC \"-//NLM//DTD esearch 20060628//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20060628/esearch.dtd\">\\n<eSearchResult>\\n\\t<Count>5095</Count>\\n</eSearchResult>\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run API query here\n",
    "\n",
    "import urllib.request # default library for requesting data from URLs\n",
    "\n",
    "# this is the base URL for making use of the NIH NLM database search API\n",
    "u_eutils = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "\n",
    "##### all of the code that follows is to construct the full search URL #####\n",
    "\n",
    "# what database to search; here, pubmed\n",
    "u_db = 'db=pubmed'\n",
    "\n",
    "# what information to return; here, count of the number of articles\n",
    "u_rettype = 'rettype=count'\n",
    "\n",
    "# what field to search; here, tiab (pubmed's code for TItle and ABstract)\n",
    "u_field = 'field=ti'\n",
    "\n",
    "# what term(s) to search for; here \"working memory\" OR \"short term memory\"\n",
    "# note that the double quotes around the phrases indicate we only want to return\n",
    "    # searches that contain that exact phrase\n",
    "u_term = 'term='\n",
    "url_searchterms = '\"dentate gyrus\" OR \"entorhinal cortex\" OR \"subiculum\"'\n",
    "url_searchterms = url_searchterms.replace(' ', '+') # URLs don't do spaces; replace with +\n",
    "u_term = u_term + url_searchterms\n",
    "\n",
    "# stitch the URL together from the parts we gave it\n",
    "url = u_eutils + '?' + u_db + '&' + u_rettype + '&' + u_field + '&' + u_term\n",
    "\n",
    "##### end URL construction block #####\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    xml = response.read()\n",
    "xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8668e07ba797e395fbcdf26f8ba26c1d",
     "grade": false,
     "grade_id": "cell-3963a9249af0b851",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create number_of_articles here\n",
    "number_of_articles = 5095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d16e66f398ed561c2d52073a2432e2a4",
     "grade": true,
     "grade_id": "cell-54c47de7ad67b3af",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q1 (worth 5 points)\n",
    "assert isinstance(u_field,str)\n",
    "assert isinstance(url_searchterms,str)\n",
    "assert isinstance(url,str)\n",
    "assert isinstance(number_of_articles,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a194f39dd550d9ad082416a38245ebe",
     "grade": true,
     "grade_id": "cell-96efe836ba4d28aa",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests for Q1 (worth 5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f9643a7b7b78850475b2f98e1170f04",
     "grade": true,
     "grade_id": "cell-91e9689f112f83dc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests for Q1 (worth 5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b04b35c3a757dce49ad563b3f27e34b",
     "grade": true,
     "grade_id": "cell-7f45cca832af3943",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Additional hidden tests for Q1 (worth 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67cd6b1daa1736ad06ece0fc86e199df",
     "grade": false,
     "grade_id": "cell-bc8692f4860bde86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2: Basic literature scanner (LISC) usage\n",
    "\n",
    "Now, instead of all of this manual URL construction, we're going to take advanatage of an open-source toolbox from Tom Donoghue and the Voytek lab here at UC San Diego called LISC (for LIterature SCanner). It's available for pip install from pypi [here](https://pypi.org/project/lisc/).\n",
    "\n",
    "You can install it on your own system by opening your terminal, going into your Pyton environment, and typing the following:\n",
    "\n",
    "<code>pip install lisc</code>\n",
    "\n",
    "Or, you can install it in this Jupyter notebook by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lisc in /home/adfrankl/.local/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages (from lisc) (4.4.1)\n",
      "Requirement already satisfied: nltk in /home/adfrankl/.local/lib/python3.6/site-packages (from lisc) (3.4.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.6/site-packages (from lisc) (4.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from lisc) (2.12.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lisc) (1.17.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk->lisc) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --user lisc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c172a6c23a4d4e5762e221fea029480f",
     "grade": false,
     "grade_id": "cell-829777d33ba816e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Demonstration of LISC\n",
    "The below cell is all of the LISC imports you'll need.\n",
    "\n",
    "Here, we create a list called <code>terms_a</code>, that contains the same three search terms we used above:\n",
    "\n",
    "* dentate gyrus\n",
    "* entorhinal cortex\n",
    "* subiculum\n",
    "\n",
    "Note the double quotes around the phrases. This time we're passing an argument for field that searches both titles and abstracts (<code>field='tiab'</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lisc import Counts\n",
    "from lisc.utils.db import SCDB\n",
    "from lisc.plts.counts import *\n",
    "\n",
    "terms_a = [['\"dentate gyrus\"'], ['\"entorhinal cortex\"'], ['\"subiculum\"']]\n",
    "\n",
    "# Initialize counts object and use the add_terms method to add terms that we want to search\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_a)\n",
    "\n",
    "# Collect data using the run_collection method\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "# Check how many articles were found for each search term\n",
    "counts.check_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "`check_counts` is a(n):\n",
    "\n",
    "* `A` attribute of `counts`\n",
    "* `B` method of `counts`\n",
    "* `C` inherited class of `counts`\n",
    "\n",
    "Write your answer below as a new variable, <code>q2_answer</code>. So if the answer was a hypothetical option <code>D</code>, you would write:\n",
    "â€‹\n",
    "<code>q2_answer = 'D'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08bde6141e1159d62ba78723847bfb47",
     "grade": false,
     "grade_id": "cell-43e81e8682b5c1b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "q2_answer = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8c2c1f65a9055196fde3d7960200b6b",
     "grade": true,
     "grade_id": "cell-ade9472e1101f50f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q2 (worth 5 points)\n",
    "\n",
    "assert isinstance(q2_answer,str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "1. Create a new list called <code>terms_b</code>, that contains the four lobes of the brain: 'frontal lobe', 'temporal lobe', 'parietal lobe', and 'occipital lobe'. Remember the double quotes around the phrases.\n",
    "2. Create a new variable, <code>number_of_lobes_articles</code>, that is equal to the *total* number of articles (as an integer) that mention any of those phrases in their titles or abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5c9165b46b8ef12fe72531651eef80e",
     "grade": false,
     "grade_id": "cell-0cccd1557823b047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run your LISC query here\n",
    "terms_b = [['\"frontal lobe\"'],['\"temporal lobe\"'],['\"parietal lobe\"'],['\"occipital lobe\"']]\n",
    "# Initialize counts object and use the add_terms method to add terms that we want to search\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_b)\n",
    "\n",
    "# Collect data using the run_collection method\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "# Check how many articles were found for each search term\n",
    "counts.check_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67b351433a849adb76c88199ae0d1ebd",
     "grade": false,
     "grade_id": "cell-cd33a4d9813aa339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign number_of_lobes_articles here\n",
    "number_of_lobes_articles = 63373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bbf255090b348fa1a932d26a3589ca2",
     "grade": true,
     "grade_id": "cell-7c20250c131d47d4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q3, wroth 5 points\n",
    "assert isinstance(counts,object)\n",
    "assert isinstance(number_of_lobes_articles,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b68722ae62edf0d69380181f05fbf2ed",
     "grade": true,
     "grade_id": "cell-e84ad3a097c3031e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests, worth 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d74cc70d2a6c3ea877a73b1e70d5f62",
     "grade": false,
     "grade_id": "cell-1b57b115e0186b2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## LISC: Term co-occurances\n",
    "LISC not only finds the counts for each search time, but also runs each pairwise comparison between terms to find how many papers are published that talk about <code>term_i</code> <em>and</em> <code>term_j</code>. This is reported as an array in <code>counts.counts</code> where each <em>i,j</em> index is how many papers are published that mention <code>term_i</code> with <code>term_j</code>.\n",
    "\n",
    "For example, for the four lobes, we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top row and left column are co-occurances for the the zeroth item in our list, \"frontal lobe\", with itself and all other terms. You'll note that LISC sets a term as having 0 publications matching with itself, by convention. You see that there are more papers published that mention \"frontal lobe\" with \"parietal lobe\" (>6500 together) than either of the other two lobes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ae2cd68814d63d46235055eaca71bae",
     "grade": false,
     "grade_id": "cell-c72a301c42bb36b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4\n",
    "Using LISC and the <code>terms_a</code> list, store the <code>counts.counts</code> array as a new variable, <code>cooccurance_matrix</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f7896044e5e27d8a9dc0632af8d79a0",
     "grade": false,
     "grade_id": "cell-b832df074d20ae47",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize counts object and add the terms that we want to search\n",
    "counts = Counts()\n",
    "counts.add_terms(terms_a)\n",
    "\n",
    "# Collect data using the run_collection method\n",
    "counts.run_collection(verbose=True, db='pubmed', field='tiab')\n",
    "\n",
    "cooccurance_matrix = counts.counts\n",
    "cooccurance_matrix\n",
    "\n",
    "plot_matrix(cooccurance_matrix, counts.terms['A'].labels, counts.terms['A'].labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6731185019f772689c06a2a6efc11794",
     "grade": true,
     "grade_id": "cell-0e62aed37f8722c7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q4 (worth 5 points)\n",
    "import numpy as np\n",
    "assert isinstance(cooccurance_matrix,np.ndarray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5\n",
    "At this point, you might have noticed that the output of counts is an numpy array. Use the cell below to assign the **shape** of your numpy array to a variable `matrix_shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86c693c1a44ca1c77aca501dbd2cb207",
     "grade": false,
     "grade_id": "cell-8ef3fbc6ecff9b5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "matrix_shape = cooccurance_matrix.shape\n",
    "matrix_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b3e1bfe324fa29fa23dc8d003d1bba7",
     "grade": true,
     "grade_id": "cell-5f0777c01bb269c8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q5, worth 5 points\n",
    "assert isinstance(matrix_shape,tuple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6\n",
    "Which pair has the most papers published talking about them together?\n",
    "\n",
    "* <code>A</code>: dentate gyrus with entorhinal cortex\n",
    "* <code>B</code>: dentate gyrus with subiculum\n",
    "* <code>C</code>: entorhinal cortex with subiculum\n",
    "\n",
    "Write your answer below as a new variable, <code>q6_answer</code>. So if the answer was a hypothetical option <code>D</code>, you would write:\n",
    "\n",
    "<code>q6_answer = 'D'</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862f1ea5ed2bdf431aed6529c26ebca9",
     "grade": false,
     "grade_id": "cell-43e81e8682b5c1b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "q6_answer = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a7ff16abbe1057798f82e1b9e985897",
     "grade": true,
     "grade_id": "cell-ade9472e1101f50e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for Q6 (worth 5 points)\n",
    "\n",
    "assert isinstance(q6_answer,str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
